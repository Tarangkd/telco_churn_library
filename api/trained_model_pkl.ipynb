{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src_telco_churn folder to the system path\n",
    "import sys\n",
    "sys.path.append('./src_telco_churn')\n",
    "\n",
    "# Now import the necessary modules\n",
    "from src_telco_churn.data_loader import CSVDataLoader, DataPreparer  \n",
    "from src_telco_churn.modeling import CrossValidator, TrainTestSplit, LogisticRegressionModel, HyperparameterTuner, ModelingPipeline\n",
    "from src_telco_churn.preprocessor import HandleMissingValues,NormalizeData, EncodeCategoricalData, HandleOutliers,PreprocessingPipeline\n",
    "from src_telco_churn.feature_engineering import (StatisticalFeatures, CategoricalEncoding, InteractionFeatures, TemporalFeatures, DerivedFeatures,FeaturePipeline)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib  # Import joblib for saving the model\n",
    "\n",
    "# Step 1: Load the data\n",
    "# Initialize the CSVDataLoader with required columns\n",
    "required_columns = ['gender', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']  # Adjust to your dataset\n",
    "csv_loader = CSVDataLoader(required_columns=required_columns)\n",
    "preparer = DataPreparer(loaders=[csv_loader])\n",
    "                        \n",
    "# Load and validate the dataset\n",
    "file_path = '/Users/tarangkadyan/Downloads/telco_churn_library/Data/data.csv'  # Provide the correct path to your data\n",
    "data = preparer.load_and_validate(file_path, loader_type=\"csv\")\n",
    "data.head()\n",
    "\n",
    "#Step-2:  Preprocessing data\n",
    "# Initialize the preprocessing pipeline\n",
    "pipeline = PreprocessingPipeline(preprocessors=[\n",
    "    HandleMissingValues(strategy='mean'),  # Impute missing values with the mean\n",
    "    NormalizeData(method='minmax'),         # Normalize data using MinMax scaling\n",
    "    EncodeCategoricalData(),               # One-hot encode categorical variables\n",
    "    HandleOutliers(method='iqr')           # Handle outliers using IQR method\n",
    "])\n",
    "\n",
    "# Apply preprocessing to the data\n",
    "processed_data = pipeline.apply(data)\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(processed_data.head())\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "pipeline = FeaturePipeline(transformers=[\n",
    "    StatisticalFeatures(group_by_column=None),\n",
    "    CategoricalEncoding(),\n",
    "    InteractionFeatures(),\n",
    "    TemporalFeatures(),\n",
    "    DerivedFeatures()\n",
    "])\n",
    "\n",
    "# Apply feature engineering to the processed data\n",
    "df_transformed = pipeline.apply(processed_data)\n",
    "\n",
    "# Step 4: Split the data into train and test sets\n",
    "features_data = df_transformed  # Use the feature-engineered data\n",
    "X = features_data.drop(columns='Churn')  # Adjust target column name as needed\n",
    "y = features_data['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train the model\n",
    "model_trainer = ModelTrainer()\n",
    "model = model_trainer.train_model(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model_evaluator = ModelEvaluator(model)\n",
    "evaluation_results = model_evaluator.evaluate_model(X_test, y_test)\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save the trained model to a pickle file\n",
    "joblib.dump(model, \"trained_model.pkl\")\n",
    "\n",
    "print(\"Model saved successfully as 'trained_model.pkl'\")\n",
    "\n",
    "# Step 8: Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
